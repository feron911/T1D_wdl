{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-11-da32d938f8ed>, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-da32d938f8ed>\"\u001b[1;36m, line \u001b[1;32m50\u001b[0m\n\u001b[1;33m    if not rs_hla_list:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import json, os, sys, argparse, gzip, glob\n",
    "\n",
    "def get_vcfs_file_list(files_dir):\n",
    "    file_list = []\n",
    "    filename_list = []\n",
    "    for root, dirs, files in os.walk(files_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".vcf.gz\"):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "                filename_list.append(file)\n",
    "                    \n",
    "    return file_list, filename_list\n",
    "\n",
    "\n",
    "def write_kourami_result_for_sample(out_dir, vcf_filename, rs_hla_list):\n",
    "    DQA1, DQB1 = [], []\n",
    "    path_to_kourami_file = os.path.join(out_dir, f\"{vcf_filename}.kourami\")\n",
    "    if len(rs_hla_list) > 2:\n",
    "        raise ValueError(f\"More than four HLA alleles for {vcf_filename} sample were typed. {rs_hla_h}\")\n",
    "    else:\n",
    "        for hla_allele in rs_hla_list:\n",
    "            DQA1.append(hla_allele.split(\";\")[0])\n",
    "            DQB1.append(hla_allele.split(\";\")[1])\n",
    "            \n",
    "    DQA1.extend(DQB1)\n",
    "    with open(path_to_kourami_file, 'w') as kourami_res:\n",
    "        for allele in DQA1:\n",
    "            allele = allele.split(\"-\")[1] + \":01G\\n\"\n",
    "            kourami_res.write(allele)\n",
    "        \n",
    "    return path_to_kourami_file\n",
    "\n",
    "def get_sampleID_rs_hla_list(vcf_file, rs_hla_dict):\n",
    "    rs_hla_list = []\n",
    "    with gzip.open(vcf_file, \"rt\") as vcf_file:\n",
    "        for line in vcf_file:\n",
    "            if line.startswith(\"#CHROM\"):\n",
    "                sample_id = line.split()[-1]\n",
    "            elif line.startswith(\"chr6\"):\n",
    "                if line.split()[2] in rs_hla_dict.keys():\n",
    "                    rs_hla_list.append(rs_hla_dict[line.split()[2]])\n",
    "            elif line.startswith(\"chr7\"):\n",
    "                break\n",
    "    \n",
    "    if not rs_hla_list:\n",
    "        rs_hla_list.append(rs_hla_dict[\"default\"])\n",
    "        rs_hla_list.append(rs_hla_dict[\"default\"])\n",
    "    \n",
    "    return sample_id, rs_hla_list\n",
    "    \n",
    "\n",
    "def write_json(vcf_file, sample_ID, path_to_copy, copy, phenotype, genome_ver, \n",
    "                   summary_stat, kourami_res, HLA_inter, HLA_standalone, script_estimate_hla, out_dir, vcf_filename):\n",
    "    base = \"PRS_single_sample_calculation.\"\n",
    "    dict_to_json = {\n",
    "        base + \"vcf\": vcf_file,\n",
    "        base + \"ID\": sample_ID.replace(\"_\", \"-\"),\n",
    "        base + \"path_to_copy\": path_to_copy,\n",
    "        base + \"copy\": copy,\n",
    "        base + \"phenotype\": phenotype,\n",
    "        base + \"genome_version\": genome_ver,\n",
    "        base + \"summary_stat\": summary_stat,\n",
    "        base + \"kuorami_results\": kourami_res,\n",
    "        base + \"HLA_interaction\": HLA_inter,\n",
    "        base + \"HLA_standalone\": HLA_standalone,\n",
    "        base + \"script_estimate_hla\": script_estimate_hla\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(out_dir, f\"{vcf_filename}.json\"), 'w') as input_file:\n",
    "        input_file.write(json.dumps(dict_to_json))\n",
    "    \n",
    "\n",
    "def main(args):\n",
    "    parser = argparse.ArgumentParser(description='Script for generating inputs for wdl script')\n",
    "    parser.add_argument(\"-vd\", '--path_to_vcfs_dir', type=str, required=True,\n",
    "                        help='Path to directory with vcfs file.')\n",
    "    parser.add_argument(\"-od\", \"--output_dir\", type=str,\n",
    "                        default=\"/home/vcheranev/wdl_inputs_files/\",\n",
    "                        help=\"Full path to output directory.\")\n",
    "    parser.add_argument(\"--copy_path\", type=str,\n",
    "                        default=\"/home/vcheranev/wdl_results/\",\n",
    "                        help=\"Path to coping results.\")\n",
    "    parser.add_argument(\"--no_copy\", action=\"store_false\",\n",
    "                        help=\"Path to HLA-HD tool directory.\")\n",
    "    parser.add_argument(\"--phenotype\", nargs=\"+\",\n",
    "                        default=[\"T1D\"],\n",
    "                        help=\"Phenotype of patients.\")\n",
    "    parser.add_argument(\"--genome_version\", type=str,\n",
    "                        default=\"hg38\",\n",
    "                        help=\"Path to hlaScan tool directory.\")\n",
    "    parser.add_argument(\"--summary_stat\", nargs=\"+\",\n",
    "                        default=[\"/home/vcheranev/PRS/PRS_calculation_summary_stat/TD1/sharp_2019/PGS000024_SNPs.tsv\"],\n",
    "                        help=\"Path to weights of SNV combination.\")\n",
    "    parser.add_argument(\"--kourami_res\", type=str,\n",
    "                        default=\"\",\n",
    "                        help=\"Path to kourami result file.\")\n",
    "    parser.add_argument(\"--HLA_interaction\", type=str,\n",
    "                        default=\"/home/vcheranev/PRS/PRS_calculation_summary_stat/TD1/sharp_2019/PGS000024_HLA_combination.tsv\",\n",
    "                        help=\"Path to weights of HLA combination.\")\n",
    "    parser.add_argument(\"--HLA_standalone\", type=str,\n",
    "                        default=\"/home/vcheranev/PRS/PRS_calculation_summary_stat/TD1/sharp_2019/PGS000024_HLA_standalone.tsv\",\n",
    "                        help=\"Path to weights of HLA standalone.\")\n",
    "    parser.add_argument(\"--script_estimate_hla\", default=\"/home/vcheranev/PRS/HLA_impact_PRS.py\",\n",
    "                        help=\"Path to script which process hla results.\")\n",
    "    parser.add_argument(\"-j\", \"--rs_hla_json_path\", type=str, \n",
    "                        default=\"/home/vcheranev/PRS/PGS000024.json\",\n",
    "                        help=\"Full path to json file with rsID and HLA allele.\")\n",
    "    args = parser.parse_args(args)\n",
    "    files_dir = args.path_to_vcfs_dir\n",
    "    out_dir = args.output_dir\n",
    "    copy_path = args.copy_path\n",
    "    kourami_res = args.kourami_res\n",
    "    script_estimate_hla = args.script_estimate_hla\n",
    "    rs_hla = args.rs_hla_json_path\n",
    "    \n",
    "    vcf_files, vcf_filenames = get_vcfs_file_list(files_dir)\n",
    "    \n",
    "    with open(rs_hla, \"r\") as j:\n",
    "        rs_hla_dict = json.loads(j.read())\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    if not os.path.exists(copy_path):\n",
    "        os.makedirs(copy_path)\n",
    "    \n",
    "    for vcf_file, vcf_filename in zip(vcf_files, vcf_filenames):\n",
    "        sample_ID, rs_hla_list = get_sampleID_rs_hla_list(vcf_file, rs_hla_dict)\n",
    "        kourami_res = write_kourami_result_for_sample(out_dir, vcf_filename, rs_hla_list)\n",
    "        write_json(vcf_file, sample_ID, copy_path, args.no_copy, args.phenotype, args.genome_version, \n",
    "                   args.summary_stat, kourami_res, args.HLA_interaction, args.HLA_standalone, script_estimate_hla, out_dir, \\\n",
    "                   vcf_filename)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
